#!/usr/bin/env python3
"""Backtest a generated MQ4 strategy using historical market data.

The original project included a very small helper to replay tick data and
compute a few metrics.  For CI we need a slightly more realistic engine that
can also read model parameters (coefficients and thresholds) and account for
execution costs.  The script implemented here parses parameters from a
generated MQ4 or JSON file and replays them on historical market data
(`trades_raw.csv` style or tick data).

During the replay it simulates basic order execution with configurable
slippage and per-trade fees.  From the resulting equity curve we compute win
rate, profit factor, maximum drawdown, Sharpe ratio and simple latency
statistics.  Results are written to ``backtest_report.json`` and an optional
CSV file.  The CLI can enforce minimum performance thresholds which will
cause a non-zero exit code â€“ useful to fail CI when a model regresses.
"""

import argparse
import csv
import json
import re
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from statistics import mean, pstdev
from typing import Dict, List, Sequence, Optional


@dataclass
class MarketRow:
    """Single row of historical market data."""

    time: str
    bid: float
    ask: float
    latency: float
    features: List[float]


def load_strategy_params(path: Path) -> Dict[str, float]:
    """Extract parameters from a generated MQ4 or JSON file.

    The parser understands a very small subset of the code generated by other
    tools in this repository.  Parameters may be supplied either through the
    MQ4 source or a JSON file with keys ``coefficients`` and ``threshold``.
    Additional optional keys are ``slippage`` and ``fee`` which represent per
    trade execution costs.
    """

    text = path.read_text()
    params: Dict[str, float] = {}

    # Common parameters
    m = re.search(r"MagicNumber\s*=\s*(\d+)", text)
    if m:
        params["magic"] = int(m.group(1))

    m = re.search(r"ModelThreshold\s*=\s*([0-9eE+\-.]+)", text)
    if m:
        try:
            params["threshold"] = float(m.group(1))
        except ValueError:
            pass

    # Coefficients from MQ4: double Coefficients[] = {0.1, -0.2, ...};
    m = re.search(r"Coefficients\s*\[\]\s*=\s*\{([^}]+)\}", text)
    if m:
        try:
            params["coefficients"] = [float(x) for x in m.group(1).split(",")]
        except ValueError:
            pass

    # If JSON content (from model.json) is provided
    if path.suffix.lower() == ".json":
        try:
            obj = json.loads(text)
            if "magic" in obj:
                params.setdefault("magic", int(obj["magic"]))
            if "threshold" in obj:
                params.setdefault("threshold", float(obj["threshold"]))
            if "coefficients" in obj:
                params.setdefault(
                    "coefficients", [float(x) for x in obj["coefficients"]]
                )
            if "slippage" in obj:
                params.setdefault("slippage", float(obj["slippage"]))
            if "fee" in obj:
                params.setdefault("fee", float(obj["fee"]))
        except json.JSONDecodeError:
            pass

    return params


def load_ticks(file: Path) -> List[MarketRow]:
    """Load semicolon separated market data.

    The CSV may contain additional feature columns prefixed with ``f`` as well
    as an optional ``latency`` column.  Unknown columns are ignored.
    """

    rows: List[MarketRow] = []
    with open(file, newline="") as f:
        reader = csv.DictReader(f, delimiter=";")
        for r in reader:
            features: List[float] = []
            for key in sorted(r.keys()):
                if key.startswith("f"):
                    try:
                        features.append(float(r[key]))
                    except (TypeError, ValueError):
                        features.append(0.0)
            rows.append(
                MarketRow(
                    time=r.get("time", ""),
                    bid=float(r.get("bid", 0) or 0),
                    ask=float(r.get("ask", 0) or 0),
                    latency=float(r.get("latency", 0) or 0),
                    features=features,
                )
            )
    return rows


def backtest(
    ticks: Sequence[MarketRow],
    coefficients: Sequence[float],
    threshold: float = 0.0,
    slippage: float = 0.0,
    fee: float = 0.0,
) -> Dict[str, float]:
    """Replay market data applying a simple linear strategy.

    ``coefficients`` are multiplied with the feature vector of each row.  If the
    resulting signal is greater than ``threshold`` a long trade is opened.  If
    the signal is below ``-threshold`` a short trade is opened.  Trades are
    closed on the following tick.  ``slippage`` represents an absolute price
    adjustment (added for longs, subtracted for shorts) and ``fee`` is a flat
    per-trade cost.
    """

    if len(ticks) < 2:
        return {
            "trade_count": 0,
            "win_rate": 0.0,
            "profit_factor": 0.0,
            "drawdown": 0.0,
            "sharpe": 0.0,
            "avg_profit": 0.0,
            "avg_latency": 0.0,
            "max_latency": 0.0,
        }

    trades: List[float] = []
    latencies: List[float] = []
    equity = 0.0
    peak = 0.0
    max_dd = 0.0

    for cur, nxt in zip(ticks[:-1], ticks[1:]):
        signal = sum(c * f for c, f in zip(coefficients, cur.features))
        direction = 0
        if signal > threshold:
            direction = 1  # long
        elif signal < -threshold:
            direction = -1  # short
        if direction == 0:
            continue

        latencies.append(cur.latency)

        if direction == 1:
            open_price = cur.ask + slippage
            close_price = nxt.bid - slippage
            profit = close_price - open_price
        else:
            open_price = cur.bid - slippage
            close_price = nxt.ask + slippage
            profit = open_price - close_price

        profit -= fee
        trades.append(profit)
        equity += profit
        peak = max(peak, equity)
        max_dd = max(max_dd, peak - equity)

    trade_count = len(trades)
    if trade_count == 0:
        return {
            "trade_count": 0,
            "win_rate": 0.0,
            "profit_factor": 0.0,
            "drawdown": 0.0,
            "sharpe": 0.0,
            "avg_profit": 0.0,
            "avg_latency": 0.0,
            "max_latency": 0.0,
        }

    wins = sum(1 for p in trades if p > 0)
    gross_profit = sum(p for p in trades if p > 0)
    gross_loss = -sum(p for p in trades if p < 0)
    win_rate = wins / trade_count
    profit_factor = (gross_profit / gross_loss) if gross_loss else float("inf")
    avg_profit = mean(trades)
    sd = pstdev(trades) if trade_count > 1 else 0.0
    sharpe = (avg_profit / sd * trade_count ** 0.5) if sd > 0 else 0.0

    return {
        "trade_count": trade_count,
        "win_rate": win_rate,
        "profit_factor": profit_factor,
        "drawdown": max_dd,
        "sharpe": sharpe,
        "avg_profit": avg_profit,
        "avg_latency": mean(latencies) if latencies else 0.0,
        "max_latency": max(latencies) if latencies else 0.0,
    }


def write_report(metrics: Dict[str, float], out_file: Path) -> None:
    """Write metrics to a JSON file."""

    out_file.parent.mkdir(parents=True, exist_ok=True)
    with open(out_file, "w") as f:
        json.dump(metrics, f, indent=2)


def update_metrics_csv(metrics: Dict[str, float], metrics_file: Path, magic: int) -> None:
    """Append metrics to a semi-colon separated CSV file."""

    metrics_file.parent.mkdir(parents=True, exist_ok=True)
    header = [
        "time",
        "magic",
        "win_rate",
        "avg_profit",
        "trade_count",
        "drawdown",
        "sharpe",
    ]
    exists = metrics_file.exists()
    with open(metrics_file, "a", newline="") as f:
        writer = csv.writer(f, delimiter=";")
        if not exists:
            writer.writerow(header)
        writer.writerow(
            [
                datetime.utcnow().strftime("%Y.%m.%d %H:%M"),
                str(magic),
                f"{metrics['win_rate']:.6f}",
                f"{metrics['avg_profit']:.6f}",
                str(metrics['trade_count']),
                f"{metrics['drawdown']:.6f}",
                f"{metrics['sharpe']:.6f}",
            ]
        )


def run_backtest(
    params_file: Path, tick_file: Path, evaluation_out: Optional[Path] = None
) -> Dict[str, float]:
    """Convenience wrapper combining the individual steps.

    Besides returning the computed metrics the function also persists a
    backtest summary to ``evaluation.json`` located next to ``params_file``.
    Existing data in that file is preserved and merely updated with the new
    metrics so that offline scores (e.g. accuracy) remain available.
    """

    params = load_strategy_params(params_file)
    ticks = load_ticks(tick_file)
    coeffs = params.get("coefficients", [1.0])
    result = backtest(
        ticks,
        coeffs,
        params.get("threshold", 0.0),
        params.get("slippage", 0.0),
        params.get("fee", 0.0),
    )
    result["magic"] = params.get("magic", 0)

    # Persist metrics for auditing.  Merge with existing evaluation file
    # instead of overwriting so that other statistics (e.g. accuracy) survive
    # repeated backtests.
    eval_path = evaluation_out or params_file.parent / "evaluation.json"
    existing: Dict[str, float] = {}
    if eval_path.exists():
        try:
            with open(eval_path) as f:
                loaded = json.load(f)
            if isinstance(loaded, dict):
                existing = {k: float(v) for k, v in loaded.items() if isinstance(v, (int, float))}
        except Exception:
            existing = {}
    existing.update(result)
    try:
        with open(eval_path, "w") as f:
            json.dump(existing, f, indent=2)
    except Exception:  # pragma: no cover - best effort persistence
        pass

    return result


def backtest_model(model_path: Path, log_file: Path) -> Dict[str, float]:
    """Convenience helper to backtest ``model_path`` against ``log_file``.

    The function delegates to :func:`run_backtest` and returns the resulting
    Sharpe ratio and win rate.  The evaluation JSON next to ``model_path`` is
    updated as a side effect.
    """

    metrics = run_backtest(model_path, log_file)
    return {"sharpe": metrics.get("sharpe", 0.0), "win_rate": metrics.get("win_rate", 0.0)}


def check_performance(
    metrics: Dict[str, float],
    min_win_rate: float = 0.0,
    min_profit_factor: float = 0.0,
) -> None:
    """Raise ``ValueError`` if metrics fall below thresholds."""

    if metrics["win_rate"] < min_win_rate or metrics["profit_factor"] < min_profit_factor:
        raise ValueError("performance below required thresholds")


def main() -> None:
    p = argparse.ArgumentParser(description="Backtest a generated MQ4 strategy")
    p.add_argument("params_file", help="Path to MQ4 or JSON parameter file")
    p.add_argument("tick_file", help="CSV file of tick data")
    p.add_argument(
        "--report",
        default="backtest_report.json",
        help="Output report JSON file (default: backtest_report.json)",
    )
    p.add_argument("--metrics-file", help="metrics.csv to append results to")
    p.add_argument("--min-win-rate", type=float, default=0.0)
    p.add_argument("--min-profit-factor", type=float, default=0.0)
    args = p.parse_args()

    result = run_backtest(Path(args.params_file), Path(args.tick_file))

    try:
        check_performance(result, args.min_win_rate, args.min_profit_factor)
    except ValueError as exc:  # pragma: no cover - exercised via CLI
        print(str(exc), file=sys.stderr)
        write_report(result, Path(args.report))
        if args.metrics_file:
            update_metrics_csv(result, Path(args.metrics_file), result.get("magic", 0))
        sys.exit(1)

    write_report(result, Path(args.report))
    if args.metrics_file:
        update_metrics_csv(result, Path(args.metrics_file), result.get("magic", 0))


if __name__ == "__main__":  # pragma: no cover - CLI entry point
    main()
